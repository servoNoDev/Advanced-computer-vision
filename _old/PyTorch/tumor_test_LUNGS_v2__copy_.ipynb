{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import f1_score, precision_score, balanced_accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wandb\n",
    "!wandb login 5a28b268df4c40793395a35db3935741e6f49711"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# transforms_train = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(p=1),\n",
    "#     transforms.Resize((350, 180)),\n",
    "#     transforms.Grayscale(num_output_channels=1),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "# transforms_test = transforms.Compose([\n",
    "#     transforms.Resize((350, 180)),\n",
    "#     transforms.Grayscale(num_output_channels=1),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.Resize((170, 180)),\n",
    "    # transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((170, 180)),\n",
    "    # transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# train_dir = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/train/\"\n",
    "# test_dir = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/test/\"\n",
    "# val_dir = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/val/\"\n",
    "#\n",
    "# train_classa_dir = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/train/absent/\"\n",
    "# train_classb_dir = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/train/present/\"\n",
    "# # test_classa_dir = \"/home/katko/cropped_grayscale_mmodes_dataset/test/absent/\"\n",
    "# test_classa_dir = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/test/absent/\"\n",
    "# test_classb_dir = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/test/present/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_dir_new = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/test_new_minus_pleura_dataset/train_/\"\n",
    "test_dir_new = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/test_new_minus_pleura_dataset/test_/\"\n",
    "val_dir_new = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/test_new_minus_pleura_dataset/val_/\"\n",
    "\n",
    "# train_classa_dir_new = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/train/absent/\"\n",
    "# train_classb_dir_new = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/train/present/\"\n",
    "# # test_classa_dir = \"/home/katko/cropped_grayscale_mmodes_dataset/test/absent/\"\n",
    "# test_classa_dir_new = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/test/absent/\"\n",
    "# test_classb_dir_new = \"/home/katko/Documents/Katka/skola/bc/cvat_usg_lung/train_test_val_new_dataset_cropped/test/present/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(train_dir_new, transforms_train)\n",
    "test_dataset = datasets.ImageFolder(test_dir_new, transforms_test)\n",
    "val_dataset = datasets.ImageFolder(val_dir_new, transforms_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3276\n",
      "479\n",
      "940\n",
      "torch.Size([170, 180])\n",
      "tensor([[0.1804, 0.1804, 0.1804,  ..., 0.1725, 0.1765, 0.1765],\n",
      "        [0.1255, 0.1255, 0.1255,  ..., 0.1373, 0.1373, 0.1373],\n",
      "        [0.2235, 0.2235, 0.2118,  ..., 0.1765, 0.1804, 0.1804],\n",
      "        ...,\n",
      "        [0.1333, 0.1333, 0.1216,  ..., 0.1882, 0.1804, 0.1804],\n",
      "        [0.2431, 0.2431, 0.2431,  ..., 0.1961, 0.1882, 0.1882],\n",
      "        [0.2431, 0.2431, 0.2431,  ..., 0.1569, 0.1569, 0.1569]])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))\n",
    "\n",
    "print(train_dataset[0][0][0,:,:].shape)\n",
    "print(train_dataset[0][0][0,:,:])\n",
    "print(train_dataset[0][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(test_dataloader.dataset)):\n",
    "    print(test_dataloader.dataset[i][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_dataloader.dataset[40][0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(train_dataloader.dataset[340][0][0,:,:], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Train dataset size:', len(train_dataset))\n",
    "print('Test dataset size:', len(test_dataset))\n",
    "print('Val dataset size:', len(val_dataset))\n",
    "class_names = train_dataset.classes\n",
    "print('Class names:', class_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 60\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "def imshow(input, title):\n",
    "    # torch.Tensor => numpy\n",
    "    print(input.shape)\n",
    "    input = input.numpy().transpose((1, 2, 0))\n",
    "    print(input.shape)\n",
    "    # input = np.clip(input, 0, 1)\n",
    "    # print(input.shape)\n",
    "    plt.imshow(input)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "# load a batch of train image\n",
    "iterator = iter(train_dataloader)\n",
    "# visualize a batch of train image\n",
    "inputs, classes = next(iterator)\n",
    "out = torchvision.utils.make_grid(inputs[:8])\n",
    "imshow(out, title=[class_names[x] for x in classes[:8]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GrayscaleResnetTest(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=2, pretrained=True, dropout_prob=0.8):\n",
    "        super(GrayscaleResnetTest, self).__init__()\n",
    "        self.model = torchvision.models.resnet18(pretrained=pretrained)\n",
    "        self.model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # self.model.fc = nn.Sequential(\n",
    "        #     nn.Dropout(p=dropout_prob),\n",
    "        #     nn.Linear(self.model.fc.in_features, out_channels, bias=True)\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet = GrayscaleResnetTest()\n",
    "input = torch.randn((16,1,350,180))\n",
    "output = resnet(input)\n",
    "print(output.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "print(model)\n",
    "# torch.cuda.empty_cache()\n",
    "# num_features = model.fc.in_features     #extract fc layers features\n",
    "# model.fc = nn.Linear(num_features, 2) #(num_of_class == 2)\n",
    "# model = model.to(device)\n",
    "# criterion = nn.CrossEntropyLoss()  #(set loss function)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        layers = [block(self.in_channels, out_channels, stride, downsample)]\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class GrayscaleResnetTest_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GrayscaleResnetTest_v2, self).__init__()\n",
    "        self.model = ResNet(BasicBlock, [2, 2, 2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=x.shape[2:])\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = GrayscaleResnetTest()\n",
    "# model = GrayscaleResnetTest_v2()\n",
    "# print(model)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-08)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(list(model.children()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wandb.init(project=\"classification-lungsliding-pa-newdataset\")\n",
    "\n",
    "num_epochs = 16\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {} running\".format(epoch))\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.   #(set loss 0)\n",
    "    running_corrects = 0\n",
    "    # load a batch data of images\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        # print(\"INPUTS SHAPE ->\" + str(inputs.size()))\n",
    "        # conv = torch.nn.Conv2d(3, 1, 1)\n",
    "        # inputs = conv(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "        # print(\"##### LABELS #####\")\n",
    "        # print(labels)\n",
    "\n",
    "        # forward inputs and get output\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # print(\"OUT SHAPE ->\" + str(outputs.shape))\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # print(\"##### PREDS #####\")\n",
    "        # print(preds)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # get loss value and update the network weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset)\n",
    "    # wandb.log({\"Train loss\": loss, \"Train acc\":epoch_acc})\n",
    "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "\n",
    "    \"\"\" Testing Phase \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in val_dataloader:\n",
    "            # conv = torch.nn.Conv2d(3, 1, 1)\n",
    "            # print(conv(inputs).size())\n",
    "            # print(inputs.size(dim=1))\n",
    "            # inputs = conv(inputs)\n",
    "            # print(inputs.shape)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_corrects / len(val_dataset)\n",
    "\n",
    "        wandb.log({\"Test loss\": loss, \"Test acc\":epoch_acc})\n",
    "\n",
    "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "# model = GrayscaleResnetTest()\n",
    "def append_dropout(model, rate=0.8):\n",
    "    for name, module in model.named_children():\n",
    "        if len(list(module.children())) > 0:\n",
    "            append_dropout(module)\n",
    "        if isinstance(module, nn.ReLU):\n",
    "            new = nn.Sequential(module, nn.Dropout2d(p=rate, inplace=False))\n",
    "            setattr(model, name, new)\n",
    "\n",
    "append_dropout(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##########################################################################################################################################\n",
    "##################################################### TEST 2 #############################################################################\n",
    "##########################################################################################################################################\n",
    "# model = GrayscaleResnetTest()\n",
    "# model = GrayscaleResnetTest_v2()\n",
    "# wandb.watch(model)\n",
    "# print(model)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=lr, alpha=0.99, eps=1e-08)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "num_epochs = 60\n",
    "start_time = time.time()\n",
    "\n",
    "run = wandb.init(project=\"classificator-videosplit_v1\",\n",
    "           config={\n",
    "                   \"start_time\": start_time,\n",
    "                   \"layers\":3,\n",
    "                   \"optimizer\": optimizer,\n",
    "                   \"learning_rate\": lr,\n",
    "                   \"loss\":criterion,\n",
    "                   \"num_epochs\":num_epochs\n",
    "           } )\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {} running\".format(epoch))\n",
    "\n",
    "    \"\"\" Training Phase \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects / len(train_dataset)\n",
    "\n",
    "    \"\"\" Validation Phase \"\"\"\n",
    "    model.eval()\n",
    "    val_running_loss = 0.\n",
    "    val_running_corrects = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            val_running_loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "            val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(val_dataset)\n",
    "    val_epoch_acc = val_running_corrects / len(val_dataset)\n",
    "\n",
    "    # Calculate the balanced accuracy, F1 score, and precision\n",
    "    bacc = balanced_accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    wandb.log({\"Training Loss\": epoch_loss, \"Training Accuracy\":epoch_acc, \"Validation Loss\":val_epoch_loss, \"Validation Accuracy\":val_epoch_acc, \"Balanced Accuracy\":bacc, \"F1 Score\":f1, \"Precision\":precision})\n",
    "    print('Epoch: {} | Training Loss: {:.4f} | Training Accuracy: {:.4f} | Validation Loss: {:.4f} | Validation Accuracy: {:.4f} | Balanced Accuracy: {:.4f} | F1 Score: {:.4f} | Precision: {:.4f}'.format(epoch+1, epoch_loss, epoch_acc, val_epoch_loss, val_epoch_acc, bacc, f1, precision))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save = 'finalasimodel.pth'\n",
    "torch.save(model.state_dict(), save)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # \"\"\" Testing Phase \"\"\"\n",
    "model.load_state_dict(torch.load('model_adam001_60.pth'))\n",
    "print(save)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        print(labels)\n",
    "        print(preds)\n",
    "        print(\"_______________________________________________________________\")\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / len(test_dataset)\n",
    "    epoch_acc = running_corrects / len(test_dataset)\n",
    "    print('Test Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'.format(epoch_loss, epoch_acc, time.time()- start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "# \"\"\" Testing Phase \"\"\"\n",
    "model.load_state_dict(torch.load(save))\n",
    "# print(save)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_loss = running_loss / len(test_dataset)\n",
    "    epoch_acc = running_corrects / len(test_dataset)\n",
    "    epoch_f1 = metrics.f1_score(all_labels, all_preds, average='macro')\n",
    "    epoch_balanced_acc = metrics.balanced_accuracy_score(all_labels, all_preds)\n",
    "    epoch_precision = metrics.precision_score(all_labels, all_preds, average='macro')\n",
    "    print('Test Loss: {:.4f} | Test Acc: {:.4f} | F1: {:.4f} | Balanced Acc: {:.4f} | Precision: {:.4f}'.format(epoch_loss, epoch_acc, epoch_f1, epoch_balanced_acc, epoch_precision))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs, labels = test_dataloader.dataset[24]\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "labels = torch.tensor([labels]).to(device)\n",
    "inputs = inputs.unsqueeze(0)\n",
    "inputs.requires_grad = True\n",
    "print(\"##### LABELS #####\")\n",
    "print(labels)\n",
    "# forward inputs and get output\n",
    "outputs = model(inputs)\n",
    "print(\"OUT SHAPE ->\" + str(outputs.shape))\n",
    "_, preds = torch.max(outputs, 1)\n",
    "print(\"##### PREDS #####\")\n",
    "print(preds)\n",
    "loss = criterion(outputs, labels)\n",
    "# get loss value and update the network weights\n",
    "loss.backward()\n",
    "plt.imshow(inputs.grad[0].cpu().detach().permute(1,2,0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow((inputs.grad[0].cpu().detach().permute(1,2,0) - inputs.grad[0].cpu().detach().permute(1,2,0).min()) / (inputs.grad[0].cpu().detach().permute(1,2,0) - inputs.grad[0].cpu().detach().permute(1,2,0).min()) .max())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(inputs.grad[0].cpu().detach().permute(1,2,0).abs() /  (inputs.grad[0].cpu().detach().permute(1,2,0).abs().max()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(inputs.grad[0].cpu().detach().permute(1,2,0).abs() /  (inputs.grad[0].cpu().detach().permute(1,2,0).abs().max()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Testing\n",
    "model.eval()\n",
    "start_time = time.time()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "    for i, (inputs, labels) in enumerate(val_dataloader):\n",
    "        print(labels)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        print(preds)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        if i == 0:\n",
    "            print('======>RESULTS<======')\n",
    "            images = torchvision.utils.make_grid(inputs[:4])\n",
    "            imshow(images.cpu(), title=[class_names[x] for x in labels[:4]])\n",
    "    epoch_loss = running_loss / len(test_dataset)\n",
    "    epoch_acc = running_corrects / len(test_dataset)\n",
    "    print('[Test #{}] Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'.\n",
    "          format(epoch, epoch_loss, epoch_acc, time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GrayscaleResnet(nn.Module):\n",
    "    def __init__(self, in_channels=1,out_channels=2,pretrained=False):\n",
    "        super(GrayscaleResnet, self).__init__()\n",
    "        self.model = torchvision.models.resnet18(pretrained=pretrained)\n",
    "        self.model.conv1 = nn.Conv2d(in_channels,64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features,out_channels)\n",
    "        print(in_channels)\n",
    "        print(out_channels)\n",
    "        print(pretrained)\n",
    "        print(self.model.fc)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = GrayscaleResnet()\n",
    "wandb.watch(model, log_freq=10) #load resnet18 model\n",
    "print(model)\n",
    "torch.cuda.empty_cache()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()  #(set loss function)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-08)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# num_epochs = 100\n",
    "# start_time = time.time() #(for showing time)\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(\"Epoch {} running\".format(epoch))\n",
    "#     \"\"\" Training Phase \"\"\"\n",
    "#     model.train()\n",
    "#     running_loss = 0.   #(set loss 0)\n",
    "#     running_corrects = 0\n",
    "#     # load a batch data of images\n",
    "#     for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "#         # print(inputs[0][0,:,:])\n",
    "#         # print(inputs[0][0])\n",
    "#         # inputs = inputs[0][0,:,:]\n",
    "#         # print(\"INPUTS SHAPE ->\" + str(inputs.size()))\n",
    "#         # inputs.size(dim=1) = 1\n",
    "#         conv = torch.nn.Conv2d(3, 1, 1)\n",
    "#         # print(conv(inputs).size())\n",
    "#         # print(inputs.size(dim=1))\n",
    "#         inputs = conv(inputs)\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         # print(labels)\n",
    "#         torch.autograd.set_detect_anomaly(False)\n",
    "#\n",
    "#\n",
    "#         print(\"##### LABELS #####\")\n",
    "#         print(labels)\n",
    "#         # forward inputs and get output\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         # print(\"OUT SHAPE ->\" + str(outputs.shape))\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         print(\"##### PREDS #####\")\n",
    "#         print(preds)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         # get loss value and update the network weights\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * inputs.size(0)\n",
    "#         running_corrects += torch.sum(preds == labels.data)\n",
    "#\n",
    "#     epoch_loss = running_loss / len(train_dataset)\n",
    "#     epoch_acc = running_corrects / len(train_dataset)\n",
    "#     # train_losses.append(np.array(epoch_acc))\n",
    "#     print('[Train #{}] Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "#\n",
    "#     \"\"\" Testing Phase \"\"\"\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         running_loss = 0.\n",
    "#         running_corrects = 0\n",
    "#         for inputs, labels in test_dataloader:\n",
    "#             conv = torch.nn.Conv2d(3, 1, 1)\n",
    "#             # print(conv(inputs).size())\n",
    "#             # print(inputs.size(dim=1))\n",
    "#             inputs = conv(inputs)\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             running_corrects += torch.sum(preds == labels.data)\n",
    "#         epoch_loss = running_loss / len(test_dataset)\n",
    "#         epoch_acc = running_corrects / len(test_dataset)\n",
    "#         # val_losses.append(np.array(epoch_acc))\n",
    "#\n",
    "#         print('[Test #{}] Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# early stop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# num_epochs = 30   #(set no of epochs)\n",
    "# start_time = time.time() #(for showing time)\n",
    "# for epoch in range(num_epochs): #(loop for every epoch)\n",
    "#     print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
    "#     \"\"\" Training Phase \"\"\"\n",
    "#     model.train()    #(training model)\n",
    "#     running_loss = 0.   #(set loss 0)\n",
    "#     running_corrects = 0\n",
    "#     # load a batch data of images\n",
    "#     for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "#         # print(\"INPUTS SHAPE ->\" + str(inputs.shape))\n",
    "#         inputs.requires_grad=True\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         # print(\"##### LABELS #####\")\n",
    "#         # print(labels)\n",
    "#         # forward inputs and get output\n",
    "#         # optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         # print(\"OUT SHAPE ->\" + str(outputs.shape))\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         # print(\"##### PREDS #####\")\n",
    "#         # print(preds)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         # get loss value and update the network weights\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * inputs.size(0)\n",
    "#         running_corrects += torch.sum(preds == labels.data)\n",
    "#         print(inputs.grad.shape)\n",
    "#         break\n",
    "    # epoch_loss = running_loss / len(train_dataset)\n",
    "    # epoch_acc = running_corrects / len(train_dataset)\n",
    "    # print('[Train #{}] Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
    "\n",
    "    # \"\"\" Testing Phase \"\"\"\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     running_loss = 0.\n",
    "    #     running_corrects = 0\n",
    "    #     for inputs, labels in test_dataloader:\n",
    "    #         inputs = inputs.to(device)\n",
    "    #         labels = labels.to(device)\n",
    "    #         outputs = model(inputs)\n",
    "    #         _, preds = torch.max(outputs, 1)\n",
    "    #         loss = criterion(outputs, labels)\n",
    "    #         running_loss += loss.item() * inputs.size(0)\n",
    "    #         running_corrects += torch.sum(preds == labels.data)\n",
    "    #     epoch_loss = running_loss / len(test_dataset)\n",
    "    #     epoch_acc = running_corrects / len(test_dataset) * 100.\n",
    "    #     print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
