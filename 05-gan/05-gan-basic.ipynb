{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the U-Net generator\n",
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "\n",
    "        # Encoder (downsampling)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "            # nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "            # nn.BatchNorm2d(1024),\n",
    "            # nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder (upsampling)\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),\n",
    "            # nn.BatchNorm2d(512),\n",
    "            # nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()  # Output normalized between -1 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x_enc = self.encoder(x)\n",
    "        x_dec = self.decoder(x_enc)\n",
    "        # print(x.shape)\n",
    "        return x_dec\n",
    "\n",
    "# Example usage\n",
    "latent_size = 100\n",
    "img_channels = 3  # Adjust based on your dataset (e.g., 3 for RGB images)\n",
    "img_size = 64  # Adjust based on your desired image size\n",
    "generator = GeneratorUNet(1, 1)\n",
    "\n",
    "# Generate random input noise\n",
    "z = torch.randn(128, 1, 28, 28)  # Batch size of 1\n",
    "fake_images = generator(z)\n",
    "# print(fake_images.shape)  # Check the output shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_channels = img_channels\n",
    "        # self.img_size = img_size\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1),  # Adjust output size based on your needs\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5097],\n",
       "        [0.6841],\n",
       "        [0.5130],\n",
       "        [0.3640],\n",
       "        [0.4628],\n",
       "        [0.5039],\n",
       "        [0.5317],\n",
       "        [0.4412],\n",
       "        [0.5102],\n",
       "        [0.5046],\n",
       "        [0.5192],\n",
       "        [0.5257],\n",
       "        [0.5866],\n",
       "        [0.5123],\n",
       "        [0.4001],\n",
       "        [0.5463],\n",
       "        [0.4396],\n",
       "        [0.5019],\n",
       "        [0.4355],\n",
       "        [0.4701],\n",
       "        [0.6067],\n",
       "        [0.4346],\n",
       "        [0.4840],\n",
       "        [0.4237],\n",
       "        [0.4731],\n",
       "        [0.5159],\n",
       "        [0.4757],\n",
       "        [0.6613],\n",
       "        [0.5537],\n",
       "        [0.3980],\n",
       "        [0.4930],\n",
       "        [0.4292],\n",
       "        [0.4965],\n",
       "        [0.4970],\n",
       "        [0.5077],\n",
       "        [0.2646],\n",
       "        [0.4360],\n",
       "        [0.5120],\n",
       "        [0.5929],\n",
       "        [0.4995],\n",
       "        [0.5884],\n",
       "        [0.4188],\n",
       "        [0.5534],\n",
       "        [0.6215],\n",
       "        [0.4942],\n",
       "        [0.4972],\n",
       "        [0.4525],\n",
       "        [0.5334],\n",
       "        [0.3356],\n",
       "        [0.4937],\n",
       "        [0.6244],\n",
       "        [0.5359],\n",
       "        [0.4435],\n",
       "        [0.5611],\n",
       "        [0.5799],\n",
       "        [0.5966],\n",
       "        [0.4733],\n",
       "        [0.4736],\n",
       "        [0.4900],\n",
       "        [0.5056],\n",
       "        [0.2869],\n",
       "        [0.3689],\n",
       "        [0.3621],\n",
       "        [0.5512],\n",
       "        [0.5178],\n",
       "        [0.6324],\n",
       "        [0.5283],\n",
       "        [0.4012],\n",
       "        [0.3900],\n",
       "        [0.6516],\n",
       "        [0.5108],\n",
       "        [0.5028],\n",
       "        [0.5060],\n",
       "        [0.5077],\n",
       "        [0.3914],\n",
       "        [0.5769],\n",
       "        [0.4708],\n",
       "        [0.5736],\n",
       "        [0.5329],\n",
       "        [0.4659],\n",
       "        [0.4480],\n",
       "        [0.4684],\n",
       "        [0.3512],\n",
       "        [0.4540],\n",
       "        [0.4567],\n",
       "        [0.4717],\n",
       "        [0.7241],\n",
       "        [0.2493],\n",
       "        [0.6587],\n",
       "        [0.4294],\n",
       "        [0.5336],\n",
       "        [0.5206],\n",
       "        [0.5846],\n",
       "        [0.4695],\n",
       "        [0.3906],\n",
       "        [0.4059],\n",
       "        [0.5740],\n",
       "        [0.3768],\n",
       "        [0.4973],\n",
       "        [0.5746],\n",
       "        [0.6033],\n",
       "        [0.5184],\n",
       "        [0.5029],\n",
       "        [0.4851],\n",
       "        [0.2939],\n",
       "        [0.4785],\n",
       "        [0.5040],\n",
       "        [0.4148],\n",
       "        [0.5556],\n",
       "        [0.5167],\n",
       "        [0.4130],\n",
       "        [0.4659],\n",
       "        [0.4845],\n",
       "        [0.3282],\n",
       "        [0.5472],\n",
       "        [0.5986],\n",
       "        [0.5553],\n",
       "        [0.5969],\n",
       "        [0.3864],\n",
       "        [0.5139],\n",
       "        [0.4466],\n",
       "        [0.3811],\n",
       "        [0.5229],\n",
       "        [0.6247],\n",
       "        [0.3631],\n",
       "        [0.5002],\n",
       "        [0.4485],\n",
       "        [0.3596]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disk = Discriminator(1)\n",
    "disk(fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Step [200/469], D_loss: 0.0233, G_loss: 4.3621, Real Score: 0.9903, Fake Score: 0.0134\n",
      "Epoch [1/1000], Step [400/469], D_loss: 0.1407, G_loss: 5.1711, Real Score: 0.9056, Fake Score: 0.0055\n",
      "Epoch [2/1000], Step [200/469], D_loss: 0.0084, G_loss: 5.4388, Real Score: 0.9963, Fake Score: 0.0046\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 83\u001b[0m\n\u001b[1;32m     77\u001b[0m latent_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# discriminator = Discriminator(img_channels)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# generator = GeneratorUNet(img_channels, img_channels)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Train the GAN\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0002\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[78], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(discriminator, generator, dataloader, num_epochs, batch_size, latent_size, lr)\u001b[0m\n\u001b[1;32m     13\u001b[0m fixed_noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# Fixed noise for tracking generator progress\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, real_images \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     17\u001b[0m         real_images \u001b[38;5;241m=\u001b[39m real_images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# print(real_images.shape)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the training function\n",
    "import torchvision.utils as vutils\n",
    "def train(discriminator, generator, dataloader, num_epochs=50, batch_size=128, latent_size=100, lr=0.0002):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    discriminator.to(device)\n",
    "    generator.to(device)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
    "    \n",
    "    fixed_noise = torch.randn(batch_size, 1, 28, 28, device=device)  # Fixed noise for tracking generator progress\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, real_images in enumerate(dataloader):\n",
    "\n",
    "            real_images = real_images[0].to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            real_labels = torch.ones(batch_size, 1, device=device)\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "            \n",
    "            # Train discriminator with real images\n",
    "            outputs = discriminator(real_images)\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            real_score = outputs.mean().item()\n",
    "            \n",
    "            # Train discriminator with fake images\n",
    "            z = torch.randn(real_images.shape, device=device)\n",
    "            fake_images = generator(z)\n",
    "            outputs = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            fake_score = outputs.mean().item()\n",
    "            \n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            discriminator.zero_grad()\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # Train generator\n",
    "            z = torch.randn(real_images.shape, device=device)\n",
    "            fake_images = generator(z)\n",
    "            outputs = discriminator(fake_images)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "            \n",
    "            generator.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            if (i+1) % 200 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], '\n",
    "                      f'D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}, '\n",
    "                      f'Real Score: {real_score:.4f}, Fake Score: {fake_score:.4f}')\n",
    "                \n",
    "        # Save generated images for tracking progress\n",
    "        with torch.no_grad():\n",
    "            fake_samples = generator(fixed_noise).detach()\n",
    "            fake_grid = vutils.make_grid(fake_samples, nrow=8, normalize=True)\n",
    "            vutils.save_image(fake_grid, f'generated_images_epoch_{epoch+1}.png', normalize=True)\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define dataset and dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize discriminator and generator\n",
    "img_channels = 1  # Grayscale images for MNIST\n",
    "img_size = 28  # Image size for MNIST\n",
    "latent_size = 100\n",
    "\n",
    "# discriminator = Discriminator(img_channels)\n",
    "# generator = GeneratorUNet(img_channels, img_channels)\n",
    "\n",
    "# Train the GAN\n",
    "train(discriminator, generator, train_loader, num_epochs=1000, batch_size=128, latent_size=latent_size, lr=0.0002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [200/469], D_loss: 0.0197, G_loss: 4.6285, Real Score: 0.9920, Fake Score: 0.0114\n",
      "Epoch [1/50], Step [400/469], D_loss: 0.0048, G_loss: 5.5312, Real Score: 0.9988, Fake Score: 0.0035\n",
      "Epoch [2/50], Step [200/469], D_loss: 0.0060, G_loss: 5.8955, Real Score: 0.9971, Fake Score: 0.0031\n",
      "Epoch [2/50], Step [400/469], D_loss: 0.0080, G_loss: 6.3209, Real Score: 0.9946, Fake Score: 0.0026\n",
      "Epoch [3/50], Step [200/469], D_loss: 0.0240, G_loss: 5.8034, Real Score: 0.9805, Fake Score: 0.0029\n",
      "Epoch [3/50], Step [400/469], D_loss: 0.0037, G_loss: 5.9918, Real Score: 0.9991, Fake Score: 0.0028\n",
      "Epoch [4/50], Step [200/469], D_loss: 0.0037, G_loss: 6.2775, Real Score: 0.9982, Fake Score: 0.0019\n",
      "Epoch [4/50], Step [400/469], D_loss: 0.0137, G_loss: 6.0207, Real Score: 0.9977, Fake Score: 0.0112\n",
      "Epoch [5/50], Step [200/469], D_loss: 0.0148, G_loss: 5.7579, Real Score: 0.9908, Fake Score: 0.0047\n",
      "Epoch [5/50], Step [400/469], D_loss: 0.0071, G_loss: 5.9438, Real Score: 0.9976, Fake Score: 0.0047\n",
      "Epoch [6/50], Step [200/469], D_loss: 0.0067, G_loss: 6.5282, Real Score: 0.9952, Fake Score: 0.0019\n",
      "Epoch [6/50], Step [400/469], D_loss: 0.0031, G_loss: 6.4853, Real Score: 0.9989, Fake Score: 0.0020\n",
      "Epoch [7/50], Step [200/469], D_loss: 0.0097, G_loss: 6.1036, Real Score: 0.9938, Fake Score: 0.0034\n",
      "Epoch [7/50], Step [400/469], D_loss: 0.0038, G_loss: 6.1729, Real Score: 0.9986, Fake Score: 0.0024\n",
      "Epoch [8/50], Step [200/469], D_loss: 0.0035, G_loss: 6.0124, Real Score: 0.9988, Fake Score: 0.0023\n",
      "Epoch [8/50], Step [400/469], D_loss: 0.0017, G_loss: 6.5148, Real Score: 0.9998, Fake Score: 0.0015\n",
      "Epoch [9/50], Step [200/469], D_loss: 0.0017, G_loss: 6.6135, Real Score: 0.9997, Fake Score: 0.0014\n",
      "Epoch [9/50], Step [400/469], D_loss: 0.0016, G_loss: 6.8401, Real Score: 0.9996, Fake Score: 0.0012\n",
      "Epoch [10/50], Step [200/469], D_loss: 0.0020, G_loss: 6.5103, Real Score: 0.9996, Fake Score: 0.0015\n",
      "Epoch [10/50], Step [400/469], D_loss: 0.0022, G_loss: 6.9131, Real Score: 0.9990, Fake Score: 0.0011\n",
      "Epoch [11/50], Step [200/469], D_loss: 0.0020, G_loss: 7.3205, Real Score: 0.9987, Fake Score: 0.0008\n",
      "Epoch [11/50], Step [400/469], D_loss: 0.0044, G_loss: 7.4053, Real Score: 0.9962, Fake Score: 0.0006\n",
      "Epoch [12/50], Step [200/469], D_loss: 0.0017, G_loss: 6.9202, Real Score: 0.9994, Fake Score: 0.0012\n",
      "Epoch [12/50], Step [400/469], D_loss: 0.0012, G_loss: 7.7819, Real Score: 0.9993, Fake Score: 0.0005\n",
      "Epoch [13/50], Step [200/469], D_loss: 0.0391, G_loss: 6.9912, Real Score: 0.9930, Fake Score: 0.0255\n",
      "Epoch [13/50], Step [400/469], D_loss: 0.0037, G_loss: 5.9291, Real Score: 0.9994, Fake Score: 0.0030\n",
      "Epoch [14/50], Step [200/469], D_loss: 0.0028, G_loss: 7.0843, Real Score: 0.9989, Fake Score: 0.0017\n",
      "Epoch [14/50], Step [400/469], D_loss: 0.0017, G_loss: 8.3457, Real Score: 0.9990, Fake Score: 0.0007\n",
      "Epoch [15/50], Step [200/469], D_loss: 0.0020, G_loss: 7.5796, Real Score: 0.9997, Fake Score: 0.0017\n",
      "Epoch [15/50], Step [400/469], D_loss: 0.0087, G_loss: 8.6134, Real Score: 0.9990, Fake Score: 0.0076\n",
      "Epoch [16/50], Step [200/469], D_loss: 0.0020, G_loss: 7.8294, Real Score: 0.9988, Fake Score: 0.0008\n",
      "Epoch [16/50], Step [400/469], D_loss: 0.0015, G_loss: 7.8592, Real Score: 0.9993, Fake Score: 0.0007\n",
      "Epoch [17/50], Step [200/469], D_loss: 0.0021, G_loss: 7.4895, Real Score: 0.9989, Fake Score: 0.0010\n",
      "Epoch [17/50], Step [400/469], D_loss: 0.0011, G_loss: 7.7933, Real Score: 0.9996, Fake Score: 0.0006\n",
      "Epoch [18/50], Step [200/469], D_loss: 0.0009, G_loss: 8.1998, Real Score: 0.9996, Fake Score: 0.0005\n",
      "Epoch [18/50], Step [400/469], D_loss: 0.0009, G_loss: 7.8081, Real Score: 0.9997, Fake Score: 0.0006\n",
      "Epoch [19/50], Step [200/469], D_loss: 0.0022, G_loss: 9.3046, Real Score: 0.9991, Fake Score: 0.0013\n",
      "Epoch [19/50], Step [400/469], D_loss: 0.0047, G_loss: 6.4798, Real Score: 0.9982, Fake Score: 0.0028\n",
      "Epoch [20/50], Step [200/469], D_loss: 0.0013, G_loss: 7.4905, Real Score: 0.9995, Fake Score: 0.0008\n",
      "Epoch [20/50], Step [400/469], D_loss: 0.0026, G_loss: 7.7144, Real Score: 0.9979, Fake Score: 0.0005\n",
      "Epoch [21/50], Step [200/469], D_loss: 0.0007, G_loss: 7.8546, Real Score: 0.9997, Fake Score: 0.0004\n",
      "Epoch [21/50], Step [400/469], D_loss: 0.0009, G_loss: 8.0839, Real Score: 0.9995, Fake Score: 0.0004\n",
      "Epoch [22/50], Step [200/469], D_loss: 0.0009, G_loss: 7.5391, Real Score: 0.9996, Fake Score: 0.0005\n",
      "Epoch [22/50], Step [400/469], D_loss: 0.0006, G_loss: 7.7440, Real Score: 0.9999, Fake Score: 0.0005\n",
      "Epoch [23/50], Step [200/469], D_loss: 0.0005, G_loss: 8.0060, Real Score: 0.9999, Fake Score: 0.0004\n",
      "Epoch [23/50], Step [400/469], D_loss: 0.0035, G_loss: 6.7199, Real Score: 0.9980, Fake Score: 0.0015\n",
      "Epoch [24/50], Step [200/469], D_loss: 0.0021, G_loss: 6.6115, Real Score: 0.9996, Fake Score: 0.0017\n",
      "Epoch [24/50], Step [400/469], D_loss: 0.0012, G_loss: 9.3090, Real Score: 0.9993, Fake Score: 0.0005\n",
      "Epoch [25/50], Step [200/469], D_loss: 0.0011, G_loss: 8.2926, Real Score: 0.9998, Fake Score: 0.0010\n",
      "Epoch [25/50], Step [400/469], D_loss: 0.0010, G_loss: 8.0249, Real Score: 0.9996, Fake Score: 0.0006\n",
      "Epoch [26/50], Step [200/469], D_loss: 0.0007, G_loss: 8.0049, Real Score: 0.9997, Fake Score: 0.0004\n",
      "Epoch [26/50], Step [400/469], D_loss: 0.0009, G_loss: 9.6444, Real Score: 0.9996, Fake Score: 0.0005\n",
      "Epoch [27/50], Step [200/469], D_loss: 0.0057, G_loss: 9.4446, Real Score: 0.9999, Fake Score: 0.0055\n",
      "Epoch [27/50], Step [400/469], D_loss: 0.0014, G_loss: 7.8055, Real Score: 0.9998, Fake Score: 0.0012\n",
      "Epoch [28/50], Step [200/469], D_loss: 0.0018, G_loss: 7.2309, Real Score: 0.9991, Fake Score: 0.0009\n",
      "Epoch [28/50], Step [400/469], D_loss: 0.0013, G_loss: 8.9147, Real Score: 0.9996, Fake Score: 0.0009\n",
      "Epoch [29/50], Step [200/469], D_loss: 0.0009, G_loss: 7.4701, Real Score: 0.9999, Fake Score: 0.0007\n",
      "Epoch [29/50], Step [400/469], D_loss: 0.0016, G_loss: 6.4481, Real Score: 0.9999, Fake Score: 0.0014\n",
      "Epoch [30/50], Step [200/469], D_loss: 0.0007, G_loss: 7.6694, Real Score: 0.9999, Fake Score: 0.0006\n",
      "Epoch [30/50], Step [400/469], D_loss: 0.0009, G_loss: 7.3256, Real Score: 0.9999, Fake Score: 0.0008\n",
      "Epoch [31/50], Step [200/469], D_loss: 0.0060, G_loss: 6.1427, Real Score: 0.9985, Fake Score: 0.0045\n",
      "Epoch [31/50], Step [400/469], D_loss: 0.0725, G_loss: 6.8503, Real Score: 0.9999, Fake Score: 0.0332\n",
      "Epoch [32/50], Step [200/469], D_loss: 0.0008, G_loss: 7.5314, Real Score: 0.9997, Fake Score: 0.0005\n",
      "Epoch [32/50], Step [400/469], D_loss: 0.0014, G_loss: 7.4950, Real Score: 0.9995, Fake Score: 0.0009\n",
      "Epoch [33/50], Step [200/469], D_loss: 0.0008, G_loss: 7.8889, Real Score: 0.9999, Fake Score: 0.0007\n",
      "Epoch [33/50], Step [400/469], D_loss: 0.0007, G_loss: 7.5859, Real Score: 0.9999, Fake Score: 0.0006\n",
      "Epoch [34/50], Step [200/469], D_loss: 0.0015, G_loss: 8.9205, Real Score: 0.9996, Fake Score: 0.0011\n",
      "Epoch [34/50], Step [400/469], D_loss: 0.0027, G_loss: 9.0314, Real Score: 0.9986, Fake Score: 0.0013\n",
      "Epoch [35/50], Step [200/469], D_loss: 0.0005, G_loss: 9.3633, Real Score: 0.9999, Fake Score: 0.0004\n",
      "Epoch [35/50], Step [400/469], D_loss: 0.0007, G_loss: 8.5652, Real Score: 0.9999, Fake Score: 0.0006\n",
      "Epoch [36/50], Step [200/469], D_loss: 0.0004, G_loss: 8.5393, Real Score: 0.9998, Fake Score: 0.0002\n",
      "Epoch [36/50], Step [400/469], D_loss: 0.0026, G_loss: 8.4411, Real Score: 0.9986, Fake Score: 0.0012\n",
      "Epoch [37/50], Step [200/469], D_loss: 0.0004, G_loss: 8.3884, Real Score: 0.9998, Fake Score: 0.0002\n",
      "Epoch [37/50], Step [400/469], D_loss: 0.0003, G_loss: 8.3840, Real Score: 0.9999, Fake Score: 0.0003\n",
      "Epoch [38/50], Step [200/469], D_loss: 0.0017, G_loss: 10.5360, Real Score: 0.9988, Fake Score: 0.0005\n",
      "Epoch [38/50], Step [400/469], D_loss: 0.0007, G_loss: 10.3439, Real Score: 0.9997, Fake Score: 0.0004\n",
      "Epoch [39/50], Step [200/469], D_loss: 0.0009, G_loss: 9.2112, Real Score: 0.9999, Fake Score: 0.0008\n",
      "Epoch [39/50], Step [400/469], D_loss: 0.0004, G_loss: 8.6757, Real Score: 0.9999, Fake Score: 0.0003\n",
      "Epoch [40/50], Step [200/469], D_loss: 0.0011, G_loss: 9.0707, Real Score: 0.9999, Fake Score: 0.0010\n",
      "Epoch [40/50], Step [400/469], D_loss: 0.0007, G_loss: 9.8649, Real Score: 0.9999, Fake Score: 0.0006\n",
      "Epoch [41/50], Step [200/469], D_loss: 0.0007, G_loss: 8.7167, Real Score: 0.9997, Fake Score: 0.0004\n",
      "Epoch [41/50], Step [400/469], D_loss: 0.0004, G_loss: 9.4560, Real Score: 0.9998, Fake Score: 0.0002\n",
      "Epoch [42/50], Step [200/469], D_loss: 0.0003, G_loss: 10.2177, Real Score: 0.9999, Fake Score: 0.0002\n",
      "Epoch [42/50], Step [400/469], D_loss: 0.0003, G_loss: 8.8898, Real Score: 0.9999, Fake Score: 0.0001\n",
      "Epoch [43/50], Step [200/469], D_loss: 0.0012, G_loss: 8.7691, Real Score: 0.9989, Fake Score: 0.0002\n",
      "Epoch [43/50], Step [400/469], D_loss: 0.0010, G_loss: 7.5571, Real Score: 0.9996, Fake Score: 0.0006\n",
      "Epoch [44/50], Step [200/469], D_loss: 0.0047, G_loss: 8.3019, Real Score: 0.9995, Fake Score: 0.0041\n",
      "Epoch [44/50], Step [400/469], D_loss: 0.0004, G_loss: 8.2406, Real Score: 0.9999, Fake Score: 0.0003\n",
      "Epoch [45/50], Step [200/469], D_loss: 0.0012, G_loss: 10.0703, Real Score: 0.9994, Fake Score: 0.0007\n",
      "Epoch [45/50], Step [400/469], D_loss: 0.0004, G_loss: 9.6040, Real Score: 0.9999, Fake Score: 0.0002\n",
      "Epoch [46/50], Step [200/469], D_loss: 0.0017, G_loss: 9.9483, Real Score: 0.9996, Fake Score: 0.0013\n",
      "Epoch [46/50], Step [400/469], D_loss: 0.0021, G_loss: 10.3340, Real Score: 0.9996, Fake Score: 0.0017\n",
      "Epoch [47/50], Step [200/469], D_loss: 0.0004, G_loss: 11.9737, Real Score: 0.9999, Fake Score: 0.0002\n",
      "Epoch [47/50], Step [400/469], D_loss: 0.0005, G_loss: 10.2179, Real Score: 0.9997, Fake Score: 0.0001\n",
      "Epoch [48/50], Step [200/469], D_loss: 0.0003, G_loss: 10.8741, Real Score: 0.9998, Fake Score: 0.0001\n",
      "Epoch [48/50], Step [400/469], D_loss: 0.0005, G_loss: 9.8549, Real Score: 0.9997, Fake Score: 0.0002\n",
      "Epoch [49/50], Step [200/469], D_loss: 0.0003, G_loss: 9.6092, Real Score: 0.9999, Fake Score: 0.0001\n",
      "Epoch [49/50], Step [400/469], D_loss: 0.0002, G_loss: 10.3795, Real Score: 0.9999, Fake Score: 0.0000\n",
      "Epoch [50/50], Step [200/469], D_loss: 0.0041, G_loss: 11.3043, Real Score: 0.9999, Fake Score: 0.0040\n",
      "Epoch [50/50], Step [400/469], D_loss: 0.0002, G_loss: 9.5502, Real Score: 0.9999, Fake Score: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "train(discriminator, generator, train_loader, num_epochs=50, batch_size=512, latent_size=100, lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
